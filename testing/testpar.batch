#!/bin/bash
#SBATCH -n 1                # Number of cores
#SBATCH -N 1                # Ensure that all cores are on one machine
#SBATCH -t 0-01:30          # Runtime in D-HH:MM, minimum of 10 minutes
#SBATCH -p huce_intel       # Partition to submit to
#SBATCH --mem=40000         # Memory pool for all cores (see also --mem-per-cpu)
#SBATCH --array=0-127
#SBATCH -o ~/cheerio_out/parassim_test_%j.out    # File to which STDOUT will be written, %j inserts jobid       
#SBATCH -e ~/cheerio_out/parassim_test_%j.err    # File to which STDERR will be written, %j inserts jobid

source ../environments/cheereio.env #This is specific to the Harvard cluster; rewrite for yours
eval "$(conda shell.bash hook)"

end_timestamp="20190110_0000"
index=$SLURM_ARRAY_TASK_ID

ensnum=$(( index / 8 ))
corenum=$(( index % 8 + 1 ))

source activate cheerio
cd ../core
python -u par_letkf.py ${end_timestamp} ${ensnum} ${corenum} "False" >> ~/cheerio_out/letkf_${ensnum}_${corenum}.out
conda deactivate